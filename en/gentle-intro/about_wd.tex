\setchapterimage[6cm]{graphics/intro/about_wd/Pile_of_books.jpeg}
\setchapterpreamble[u]{\margintoc}
\chapter{Review Wikidata}
\labch{ch-review-wd}

\footnotetext{Hendrik Conscience Heritage Library in Antwerp. //
\href{https://commons.wikimedia.org/wiki/File:Pile_of_books.jpg}{Wikimedia Commons / Missmarettaphotography (CC BY-SA)}.}

\section{What is Wikidata?}
\labsec{section:what-wd}
Wikidata is a structured and collaboratively edited database, which was created by the Wikimedia Foundation. Wikidata is a free, collaborative, multilingual, secondary database that collects structured information to support the operation of Wikipedia, Wikimedia Commons, and other Wikimedia Foundation wiki projects. \begin{marginfigure}[3.5cm]
{
	\setlength{\fboxsep}{0pt}%
	\setlength{\fboxrule}{1pt}%
	\fcolorbox{gray}{white}{\includegraphics{./graphics/intro/about_wd/Wikidata-logo-en.png}}
}
\caption
{Wikidata logo. \newline
Wikimedia Commons / Planemad 
}
\label{fig:seyu}
\end{marginfigure}The project was officially launched on the 30th of October in 2012, and is being developed under the direction of Wikimedia Deutschlandnd~\sidecite{Wikipedia_review}. The project was created with donations from the Allen Institute for Artificial Intelligence, the Gordon and Betty Moore Foundation and Google. Wikidata is a free and open source knowledge base that can be used and edited by humans and computer programs~\sidecite{Vrandecic}.

Content on Wikidata is licensed under the Creative Commons CC0 license, which allows to reuse information in a variety of ways, allowing users to copy, modify, distribute and manipulate the data for any purposes. Another feature of Wikidata is multilingualism. Anyone can edit Wikidata in over 350 languages.

Wikidata is constantly updated, and new objects are being added. By 2021 there have been over 95 million pages created and over 1.5 billion edits made.\sidenote[][]{The data is taken from the official Wikidata statistics page: \href{https://www.wikidata.org/wiki/Wikidata:Statistics}{https://www.wikidata.org/wiki/Wikidata:Statistics}} Over \num{800000} edits were made to Wikidata during the year of 2019, which surpassed the number of edits on the English Wikipedia, making Wikidata the most edited Wikimedia site.\sidenote[][]{The official website of Wikidata: \href{https://www.wikidata.org/}{https://www.wikidata.org/}}

\section{Wikidata Query Service}
\labsec{sect:WDQS}
Any Wikidata object has its own unique identifier and properties. This information can be processed using a computer, and, in addition to that, it is understandable to users. The Wikidata site contains the ``Wikidata Query'' service, which includes a set of tools for building SPARQL queries and visualizing them in the form of tables, charts, graphs or geographic maps.

\section{About Wikidata research}
\labsec{section:research-wd}
The article ``A large-scale collaborative ontological medical database''~\sidecite{Collaborative_ontological_database} describes the benefits of using Wikidata to create a large-scale collaborative medical database. The main requirements for the described database are a platform with real-time updates, a suitable license for the subsequent use of the information obtained, free editing in any language, and open access. These are the main characteristics of Wikidata. Firstly, Wikidata is an open, editable knowledge base. Any user without programming skills can make changes in over 350 languages and dialects. Secondly, the information is constantly updated, and new objects are added. As of 2021, Wikidata has over \num{18000} editors.\sidenote[][]{For comparison, the number of active editors on Russian Wikipedia
is about \num{4000} users (\href{https://stats.wikimedia.org/\#/ru.wikipedia.org}{https://stats.wikimedia.org/\#/ru.wikipedia.org}), and there are more than \num{15000} users on on Wikimedia Commons (\href{https://stats.wikimedia.org/\#/commons.wikimedia.org}{https://stats.wikimedia.org/\#/commons.wikimedia.org}).} Thirdly, the Creative Commons CC0 license allows extensive use of the acquired information.

In fact, Wikidata has no competitors right now. However, it is customary to indicate analogs and alternatives. So, we will indicate them. There are several alternative knowledge bases:
\begin{enumerate}
\item Cyc is a project of Cycorp (Austin, USA) to create an ontological knowledge base that allows solving problems in the field of artificial intelligence~\sidecite{Cyc}. This knowledge base has some drawbacks: the complexity of the system (the complexity of adding data manually), lack of documentation for studying the system, and incompleteness of the system. 
\item Evi (formerly True Knowledgee~\sidecite{True_Knowledge}) is a technology company in Cambridge, England that specializes in knowledge base and \textit{semantic search} 
\sidenote[][]{Semantic search is a method and technology of information retrieval based on the use of the context (semantic) meaning of the requested phrases, instead of the dictionary meanings of individual words or expressions in a search query} software. Adding information to the knowledge base is done in two ways: import from ``trustworthy'' external databases (e.g., Wikipedia) and from users' views according to a uniform format and detailed input process. As with Wikipedia, the user can change
data, ``agree'' or ``disagree'' with the information provided by True Knowledge. The system can reject any facts that are semantically incompatible with other validated knowledge, as opposed to Wikidata, where inconsistent data can be stored.
\item DBPedia is a crowdsourcing project aimed at extracting structured information from data created by the Wikipedia project and publishing it as datasets available under a free license. The project was noted as one of the most efficient methods for implementing linked data.
The project was started by recruiting volunteers from the Free University of Berlin and Leipzig University, in collaboration with OpenLink Software, with the first data published in 2007. Since 2012, the University has been an active participant in the project.
\end{enumerate}
In Wikidata, information is presented in the form of objects (or elements) linked to each other using properties.\sidenote[][]{For example, the following properties exist: instance \wdProperty{31}{}, subclass \wdProperty{279}{}, part\wdProperty{361}{}, has part \wdProperty {527}{}.} The power of Wikidata in its large volume and surprisingly rapid growth and self-organization; the fact that this "alive" knowledge base can be accessed using SPARQL queries, the results of their execution can be presented in the form of tables, graphs, diagrams, or saved in the desired format (CSV, JSON, SVG).

Wikidata can take on the role of a centralized data repository. The article~\sidecite{Falcon_2.0} provides an example of using Wikidata as a centralized and public knowledge base for the FALCON 2.0 system. This system identifies entities in a short text or question and then links them with the corresponding URLs in the Wikidata knowledge graph.

\section{Ambiguity of Wikidata object}
\labsec{section:ambiguity-wd}
As stated earlier, any Wikidata object has properties. One of them is \wdProperty{31}{``an instance of''}. It defines the class to which the object belongs. The Wikidata rules and some of the articles~\sidecite{GoogleAcademy}, state that the object corresponds to one class.

However, we found that this is not always the case. It turned out that some objects are instances of completely different classes. For example, \wdqName{the Royal Swedish Academy of Sciences}{191583} is an instance of three classes at once: the Academy of Sciences, the building and the Royal Academy of Sweden. Such definition of classes is correct in this case, since this object can be considered as an organization, the purpose of which is the development of science, and also as an architectural structure.

This example relates to the lexical disambiguation or WSD problem. Many scientists have tried to tackle this task, including the Italian scientist Angela Fogarolli. In her work~\sidecite{Fogarolli}, she selects objects of ambiguity that correspond to several classes depending on the context and allows multiple classes in the ``instance of'' property.

\section{Wikidata quality and technical platform}
\labsec{section:quality-wd}
Wikidata has existed since 2012. As of 2021, project editors are more than 200 thousand users who have made more than 50 million edits.\sidenote[][]{The data is taken from the official Wikidata statistics page: \href{https://www.wikidata.org/wiki/Wikidata:Statistics}{https://www.wikidata.org/wiki/Wikidata:Statistics}}

Alessandro Piscopo's doctoral dissertation~\sidecite{Piscopo} discusses the socio-technical processes and data quality of the Wikidata project, that Wikidata users have the ability to download pieces of information, perform editing through various interfaces and work with platforms such as Wikipedia, but at the same time they are fully responsible for maintaining the knowledge graph~\sidecite{Knowledge_Graphs} schema in working order. However, this work must be carried out by a team of trained professionals in accordance with well thought out methods. These actions are carried out using the tools that form the technical basis of the system.

\textit{Bots}\sidenote[][]{For more information on bots, see the chapter ``Bots in Wikidata'' on page \pageref{ch:bots}.} are a special tool, which is used in both Wikidata and Wikipedia. These are pieces of software that can automatically perform various actions on the platform at high speed (over a thousand edits per minute). Their main task is to edit existing data, add and import new data from other resources. Bots create reports which help the users to correct inaccuracies.

Thus, bots are one of the key technical components of Wikidata. Users add and modify data and communicate with each other using the Wikidata web interface. There are also plugins available that alert editors when they are about to perform a revision that could lead to any data errors.

The article ``Network structure of scientific revolutions''~\sidecite{Network_structure_revolutions}, which, using the example of Wikipedia, examines the process of knowledge formation in the form of constantly growing networks of articles and their interconnected hyperlinks. This concept is being developed by filling knowledge gaps. The authors formulated the goal of their work in one sentence: ``The authors test theories of scientific progress on growing concept networks and reveal data-driven conditions underlying breakthroughs''~\sidecite{Network_structure_revolutions}.

In the course of the research (Zhou, Ju and Blevins, 2020)~\sidecite{Network_structure_revolutions}, all Wikipedia articles on the network were ranked according to certain criteria. Each host corresponds to a specific article, the hostname is the title of the article, the year of birth of the host is the first year listed in the introduction or in the history section as the year the concept was conceived. Then, based on the current state of the networks, some patterns were identified in the evolution of these structures over time and periods when the network changed most rapidly.

The results obtained showed that human knowledge is growing and, as a result, there is a gradual change in the network's structure (some knowledge gaps are being filled). The authors of the article)~\sidecite{Network_structure_revolutions} believe that the knowledge found during filling the gaps will be essential for scientific innovation.

This article~\sidecite{Network_structure_revolutions} is directly related to the quality of Wikidata, because the information for Wikidata is most often taken from Wikipedia. If the gaps in Wikipedia are filled, then the new data will certainly be added to Wikidata, and the knowledge base will become more complete and detailed.